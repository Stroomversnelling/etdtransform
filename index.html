

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>etdtransform - “Energietransitie Dataset” transformation and loading package documentation &mdash; etdtransform - &#34;Energietransitie Dataset&#34; transformation and loading package 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=01f34227"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="etdtransform" href="source/modules.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            etdtransform - "Energietransitie Dataset" transformation and loading package
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Functions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="source/modules.html">etdtransform</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">etdtransform - "Energietransitie Dataset" transformation and loading package</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">etdtransform - “Energietransitie Dataset” transformation and loading package documentation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="etdtransform-energietransitie-dataset-transformation-and-loading-package-documentation">
<h1>etdtransform - “Energietransitie Dataset” transformation and loading package documentation<a class="headerlink" href="#etdtransform-energietransitie-dataset-transformation-and-loading-package-documentation" title="Link to this heading"></a></h1>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Functions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="source/modules.html">etdtransform</a></li>
</ul>
</div>
<section id="about-etdtransform">
<h2>About etdtransform<a class="headerlink" href="#about-etdtransform" title="Link to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">etdtransform</span></code> package provides the required helpers to work with the <code class="docutils literal notranslate"><span class="pre">Energietransitie</span> <span class="pre">Dataset</span></code> (ETD). The ETD is a model defining important variables for energy in the built environment, which are used to inform policy and planning decisions in the Netherlands. For an overview of the ETD and all documentation, see <a href="https://energietransitiedataset.nl/">https://energietransitiedataset.nl/</a>.</p>
<p>It depends on <code class="docutils literal notranslate"><span class="pre">etdmap</span></code> for the ETD data model definitions and for some data loading functions. It is expected that any datasets used have already been mapped and undergone basic quality control. See <code class="docutils literal notranslate"><span class="pre">etdmap</span></code> for more information.</p>
</section>
<section id="license">
<h2>License<a class="headerlink" href="#license" title="Link to this heading"></a></h2>
<p>The package may only be used for open processing. You agree to publicly share the intended application, obtained insights, and applied calculation methods under the same license.</p>
</section>
<section id="citation">
<h2>Citation<a class="headerlink" href="#citation" title="Link to this heading"></a></h2>
<p>If you use this package or any code in this package or refer to output, please use the following citations for attribution:</p>
<p><em>Witkamp, Dickinson, Izeboud (2024). etdtransform: A Python package for improving the data quality of data in the Energietransitie Dataset (ETD) model.</em></p>
</section>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Link to this heading"></a></h2>
<p>If you want to use this package on its own, you can install it with pip:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/Stroomversnelling/etdtransform.git
<span class="nb">cd</span><span class="w"> </span>etdtransform
pip<span class="w"> </span>install<span class="w"> </span>.
</pre></div>
</div>
</section>
<section id="developing-and-contributing">
<h2>Developing and contributing<a class="headerlink" href="#developing-and-contributing" title="Link to this heading"></a></h2>
<p>If you would like to contribute to the package code, we would create an environment and install it in editable mode:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/Stroomversnelling/etdtransform.git
<span class="nb">cd</span><span class="w"> </span>etdtransform
python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>.venv
<span class="nb">source</span><span class="w"> </span>.venv/bin/activate<span class="w">  </span><span class="c1"># On Windows use `.venv\Scripts\activate`</span>
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
</section>
<section id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Link to this heading"></a></h2>
<p>To use most functions in this package, one needs to configure options so that the location of the mapped files created with <code class="docutils literal notranslate"><span class="pre">etdmap</span></code> and the location of aggregated data created with this package is defined up front.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">etdtransform</span>

<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">mapped_folder</span> <span class="o">=</span> <span class="s1">&#39;mapped_folder_path&#39;</span> <span class="c1"># path to folder where mapped files are stored</span>
<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>
<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">weather_folder</span> <span class="o">=</span> <span class="s1">&#39;KNMI_weather_data_folder_path&#39;</span> <span class="c1"># path to the KNMI weather data folder</span>
<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">weather_file</span> <span class="o">=</span> <span class="s1">&#39;path_to_KNMI_stations_file&#39;</span> <span class="c1"># path to the KNMI weather stations data file</span>
</pre></div>
</div>
</section>
<section id="loading-mapped-data-as-ibis-tables">
<h2>Loading mapped data as Ibis tables<a class="headerlink" href="#loading-mapped-data-as-ibis-tables" title="Link to this heading"></a></h2>
<p>Typically, we will first load data from the mapped parquet files stored in the configured folders. We prefer to load them as Ibis tables and - after selecting the appropriate columns and filtering the desired rows, and merging with other required data - transforming them to an in-memory format, such as a Pandas dataframe. This ensures that the data is loaded quickly and efficiently despite the large number of columns and records in the dataset. We will provide a few examples below.</p>
<p>There are two main types of aggregated ETD datasets:</p>
<ul class="simple">
<li><p>data for individually connected units in the built environment, such as a household or, perhaps in the future, a charging point, and</p></li>
<li><p>project level data, an aggregated collection of network connected units based on <code class="docutils literal notranslate"><span class="pre">ProjectIdBSV</span></code> and often representing a limited geographic scope, e.g. a neighborhood.</p></li>
</ul>
<p>Building units are usually a single household and may represent an apartment or other type of home. The data from building units is described in the <code class="docutils literal notranslate"><span class="pre">etdmap</span></code> package.</p>
<p>To load household data, use the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.load_data</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_household_tables</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ibis</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ibis</span><span class="w"> </span><span class="kn">import</span> <span class="n">_</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ibis.selectors</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">s</span>

<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="n">desired_interval</span> <span class="o">=</span> <span class="s1">&#39;5min&#39;</span> <span class="c1"># 5min, 15min, 60min, 24h</span>
<span class="n">tbls</span> <span class="o">=</span> <span class="n">load_household_tables</span><span class="p">()</span>

<span class="c1"># load only data for a specific interval, specific columns</span>
<span class="n">household_5min</span> <span class="o">=</span> <span class="n">tbls</span><span class="p">[</span><span class="s1">&#39;5min&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="s1">&#39;ReadingDate&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ProjectIdBSV&#39;</span><span class="p">,</span>
    <span class="s1">&#39;HuisIdBSV&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ElektriciteitNetgebruikHoog&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ElektriciteitNetgebruikLaag&#39;</span>
<span class="p">)</span>

<span class="c1"># Use selectors instead to select using the variable suffixes for &#39;ProjectIdBSV&#39;, &#39;HuisIdBSV&#39; and prefixes for &#39;ElektriciteitNetgebruikHoog&#39;, &#39;ElektriciteitNetgebruikLaag&#39;</span>
<span class="n">household_5min</span> <span class="o">=</span> <span class="n">tbls</span><span class="p">[</span><span class="s1">&#39;5min&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="s1">&#39;ReadingDate&#39;</span><span class="p">,</span>
    <span class="n">s</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;BSV&#39;</span><span class="p">),</span>
    <span class="n">s</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;ElektriciteitNetgebruik&#39;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># filter out only households from project 1.0 with a surface of 100 m2 or more</span>
<span class="n">household_5min</span> <span class="o">=</span> <span class="n">household_5min</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
    <span class="n">_</span><span class="o">.</span><span class="n">ProjectIdBSV</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">_</span><span class="o">.</span><span class="n">Oppervlakte</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># convert to pandas for further processing or graphing</span>
<span class="n">household_df</span> <span class="o">=</span> <span class="n">household_5min</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

</pre></div>
</div>
<p>Projects are a collection of connected units (mostly: homes) with similar characteristics. Often these were redeveloped at the same time using similar insulation and installation choices. It can be a proxy for a neighborhood. Each project has its own metadata.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.load_data</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_project_tables</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ibis</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ibis</span><span class="w"> </span><span class="kn">import</span> <span class="n">_</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ibis.selectors</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">s</span>

<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="n">desired_interval</span> <span class="o">=</span> <span class="s1">&#39;5min&#39;</span> <span class="c1"># 5min, 15min, 60min, 24h</span>
<span class="n">project_tbls</span> <span class="o">=</span> <span class="n">load_project_tables</span><span class="p">()</span>

<span class="c1"># load only data for a specific interval, specific columns</span>
<span class="n">project_24h</span> <span class="o">=</span> <span class="n">project_tbls</span><span class="p">[</span><span class="s1">&#39;24h&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;ReadingDate&#39;</span><span class="p">,</span><span class="s1">&#39;ProjectIdBSV&#39;</span><span class="p">,</span> <span class="s1">&#39;ElektriciteitsgebruikTotaalNetto&#39;</span><span class="p">)</span>

<span class="c1"># exclude project 6.0</span>
<span class="n">project_24h</span> <span class="o">=</span> <span class="n">household_5min</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
    <span class="n">_</span><span class="o">.</span><span class="n">ProjectIdBSV</span> <span class="o">!=</span> <span class="mf">6.0</span>
<span class="p">)</span>

<span class="c1"># convert to pandas for further processing or graphing</span>
<span class="n">project_df</span> <span class="o">=</span> <span class="n">project_24h</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

</pre></div>
</div>
<p>To load data from a set before the resampling and aggregation, it is possible to use <code class="docutils literal notranslate"><span class="pre">get_hh_table()</span></code> and pass the function the following non-standard intervals:</p>
<ul class="simple">
<li><p>default: load household data before any imputation has been done</p></li>
<li><p>imputed: load household data that has been imputed, including all <code class="docutils literal notranslate"><span class="pre">is_imputed</span></code> columns for indentifying values as imputed</p></li>
<li><p>calculated: same as ‘imputed’ but with the addition of calculated columns</p></li>
</ul>
<p>For example, to get columns that are used to calculate Electricity Net Usage <code class="docutils literal notranslate"><span class="pre">ElektriciteitsgebruikTotaalNetto</span></code> and the columns that identify if any of these values are imputed, we can do the following.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ibis</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ibis</span><span class="w"> </span><span class="kn">import</span> <span class="n">_</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ibis.selectors</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">s</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.load_data</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_hh_table</span>
<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="n">df_calculated</span> <span class="o">=</span> <span class="n">get_hh_table</span><span class="p">(</span><span class="s1">&#39;5min&#39;</span><span class="p">,</span> <span class="s1">&#39;calculated&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="s1">&#39;ReadingDate&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ProjectIdBSV&#39;</span><span class="p">,</span>
    <span class="s1">&#39;HuisIdBSV&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ElektriciteitNetgebruikHoog&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ElektriciteitNetgebruikLaag&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ElektriciteitNetgebruikHoog_is_imputed&#39;</span><span class="p">,</span> <span class="c1"># True or False</span>
    <span class="s1">&#39;ElektriciteitNetgebruikLaag_is_imputed&#39;</span><span class="p">,</span> <span class="c1"># True or False</span>
    <span class="s1">&#39;ElektriciteitsgebruikTotaalNetto&#39;</span> <span class="c1"># calculated from Hoog and Laag variables</span>
<span class="p">)</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="transformations-to-prepare-datasets-for-loading-advanced">
<h2>Transformations to prepare datasets for loading (advanced)<a class="headerlink" href="#transformations-to-prepare-datasets-for-loading-advanced" title="Link to this heading"></a></h2>
<p>After data from different data sources are mapped to the ETD data model using the <code class="docutils literal notranslate"><span class="pre">etdmap</span></code> package, data files are placed in the mapped folder. The mapped data folder contains an index file and a file per connected building unit. In order to prepare these files for loading in analytical workflows and notebooks,  we first combine all data into a single dataset and then impute missing values where possible. Finally, we aggregate and resample data into the final datasets.</p>
<p><em>While most users will not need to apply these transformations as the datasets will already have been aggregated, some of the following operations require large amounts of RAM and can surpass 100GB of RAM to run efficiently. Please consider whether you have enough RAM and time available if you are processing the data. In the future, we could reduce the RAM requirements if needed.</em></p>
<section id="combining-individual-building-unit-data">
<h3>Combining individual building unit data<a class="headerlink" href="#combining-individual-building-unit-data" title="Link to this heading"></a></h3>
<p>This step will create a single dataset and remove households marked in the household metadata to not be used (‘Meenemen’). Households with poor data, including missing variables or large amounts of missing data or other data anomolies that cannot be automatically cleaned are marked 0 so they are not included. All other households are marked 1 to include in our transformations.</p>
<p>For nearly 300 househoulds, it requires over 25GB of RAM to run efficiently. This function will save <code class="docutils literal notranslate"><span class="pre">household_default.parquet</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform</span><span class="w"> </span><span class="kn">import</span> <span class="n">aggregate_hh_data_5min</span>

<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">mapped_folder</span> <span class="o">=</span> <span class="s1">&#39;mapped_folder_path&#39;</span> <span class="c1"># path to folder where mapping files are stored</span>
<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="n">aggregate_hh_data_5min</span><span class="p">()</span> <span class="c1"># this will generate the `household_default.parquet` file in the aggregate data folder</span>
</pre></div>
</div>
</section>
<section id="imputation-to-fill-gaps">
<h3>Imputation to fill gaps<a class="headerlink" href="#imputation-to-fill-gaps" title="Link to this heading"></a></h3>
<p>Ideally, each data provider has provided 5 minute resolution for all the devices. In some cases, not all variables are available at this level of granularity and in others interval may be 15 minutes or more. In cases where data is given at 5 minute intervals, we take columns that have longer intervals and impute missing values where possible.</p>
<p>Gaps in data are filled in different ways based on the patterns we found in the raw data. There are a few different imputation techniques that are used to impute the <strong>expected change in cumulative variables</strong>:</p>
<ul class="simple">
<li><p>Filling in 0s where there is a gap in data but no subsequent change in later cumulative values</p></li>
<li><p>Filling in 0s where the cumulative value has decreased but should not normally. For example, when a cumulative energy meter counter jumps down to 0 and then increases again to the value it had before the jump to 0. The assumption is that there has been no real change and there was a data registration anomaly.</p></li>
<li><p>Filling in based on the <em>project average change</em> where there is no data in a household but data is available from other households in the same project. This average is scaled so that the total change over the missing time period matches the next available cumulative value. The scaling factor is calculated with the ratio between actual change in the household and the project average change over the same period.</p></li>
<li><p>Filling in linearly where there is insufficient data from other households to calculate an average change over the period. This is only applied on cumulative variables and when the missing data covers a small time period.</p></li>
</ul>
<p>Some of these imputation methods will reduce the variance of the dataset. Taking this into account, it is important to exclude datasets with too much missing data and consider this during analysis and interpretation as several measures such as the IQR or standard deviation may be sensitive to the imputation. By carefully selecting datasets and ensure project data is never missing from many households at any one point in time, these effects are very small.</p>
<p>When the project average change is used, the scaling factor is calculated with the ratio between:</p>
<ul class="simple">
<li><p>the difference between cumulative values in the household before and after the gap in data, e.g. if the last cumulative value was 222 and the next was 322, then the gap jump is 100, and</p></li>
<li><p>the sum of project change over the same period, e.g the average change in this variable over all households in the project, for this example taken to be 50.</p></li>
</ul>
<p>The calculated ratio would be 100/50 = 2 so each average change is multiplied by 2.0 and these scaled values are used to fill in the gap.</p>
<p>Before the average is calculated, households with outliers are removed. The upper bound is double the 95th percentile value per project per registration at a specific time. If the household maximum for the variable is within this bound, it is included in the average difference calculation. By definition, this includes 100% to 95% of households in each registered moment per project so the resulting average should be representative and useful for imputation.</p>
<section id="loading-mapped-data">
<h4>1. Loading mapped data<a class="headerlink" href="#loading-mapped-data" title="Link to this heading"></a></h4>
<p>For this step, the data is read from the <code class="docutils literal notranslate"><span class="pre">household_default.parquet</span></code> in the path provided.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">etdtransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.aggregate</span><span class="w"> </span><span class="kn">import</span> <span class="n">read_hh_data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.impute</span><span class="w"> </span><span class="kn">import</span> <span class="n">sort_for_impute</span><span class="p">,</span> <span class="n">prepare_diffs_for_impute</span><span class="p">,</span> <span class="n">impute_hh_data_5min</span>

<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">read_hh_data</span><span class="p">(</span><span class="n">interval</span> <span class="o">=</span> <span class="s1">&#39;default&#39;</span><span class="p">)</span>

</pre></div>
</div>
</section>
<section id="calculating-diff-columns-and-average-change-per-time-step">
<h4>2. Calculating diff columns and average change per time step<a class="headerlink" href="#calculating-diff-columns-and-average-change-per-time-step" title="Link to this heading"></a></h4>
<p>We prepare the imputation by first calculating the differences between the consecutive values in cumulative columns to get the change every 5 minutes. These <code class="docutils literal notranslate"><span class="pre">diff</span></code> columns will be added to the dataframe.</p>
<p>The average <code class="docutils literal notranslate"><span class="pre">diff</span></code> per 5 minutes in a project is used to impute values.  The average difference between timesteps for all cumulative variables is saved in a series of files by <code class="docutils literal notranslate"><span class="pre">prepare_diffs_for_impute()</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pre-sort rows to speed up the process</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">sort_for_impute</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">project_id_column</span><span class="o">=</span><span class="s1">&#39;ProjectIdBSV&#39;</span><span class="p">)</span>

<span class="c1"># Optional: limit the operation to only a few columns of interest - otherwise leave the `cumulative_columns` parameter out</span>
<span class="n">cum_cols_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Zon-opwekTotaal&#39;</span><span class="p">,</span> <span class="s1">&#39;ElektriciteitsgebruikWarmtepomp&#39;</span><span class="p">]</span>

<span class="n">prepare_diffs_for_impute</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">project_id_column</span><span class="o">=</span><span class="s1">&#39;ProjectIdBSV&#39;</span><span class="p">,</span> <span class="n">cumulative_columns</span><span class="o">=</span><span class="n">cum_cols_list</span><span class="p">,</span> <span class="nb">sorted</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Additional files saved to the aggregate folder are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">household_diff_max_bounds.parquet</span> </code>: maximum differences per variable and the boundary values used to exclude outliers</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">avg_diffs.parquet</span></code>: the average difference per variable per project used for imputation</p></li>
</ul>
</section>
<section id="imputation">
<h4>Imputation<a class="headerlink" href="#imputation" title="Link to this heading"></a></h4>
<p>Finally, <code class="docutils literal notranslate"><span class="pre">impute_hh_data_5min()</span></code> will save the imputed dataset in the aggregate folder.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">impute_hh_data_5min</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cum_cols</span><span class="o">=</span><span class="n">cum_cols_list</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">diffs_calculated</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Files are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">household_imputed.parquet</span></code>: the resulting imputed dataset with helper columns to identify imputation and methods of imputation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">impute_summary_project.parquet</span></code>: a summary of imputation per project</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">impute_summary_household.parquet</span></code>: a summary of imputation per household</p></li>
</ul>
<p>It is possible to use arguments to pass pre-processed or sampled households to this function and to avoid sorting the column or recalculating differences if they have already been calculated previously. This can be useful as the dataset generated is very large.</p>
<p><strong>As of Fall 2024, most of the imputation is now much faster with the use of a series of simple vectorized operations instead of applying functions over the data. The trade off is that the imputation code is a little less readable.</strong></p>
</section>
</section>
<section id="add-calculated-columns">
<h3>Add calculated columns<a class="headerlink" href="#add-calculated-columns" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.aggregate</span><span class="w"> </span><span class="kn">import</span> <span class="n">read_hh_data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.calculated_columns</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_calculated_columns_to_hh_data</span>
<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="n">df_imputed</span> <span class="o">=</span> <span class="n">read_hh_data</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="s2">&quot;imputed&quot;</span><span class="p">)</span>
<span class="n">df_calculated</span> <span class="o">=</span> <span class="n">add_calculated_columns_to_hh_data</span><span class="p">(</span><span class="n">df_imputed</span><span class="p">)</span>

</pre></div>
</div>
</section>
<section id="resampling-to-different-time-intervals">
<h3>Resampling to different time intervals<a class="headerlink" href="#resampling-to-different-time-intervals" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.aggregate</span><span class="w"> </span><span class="kn">import</span> <span class="n">read_hh_data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.calculated_columns</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_calculated_columns_to_hh_data</span>
<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="c1"># all files are saved to household_[interval].parquet in the aggregate folder, e.g. household_5min.parquet</span>
<span class="n">resample_hh_data</span><span class="p">(</span><span class="n">intervals</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;5min&quot;</span><span class="p">])</span> <span class="c1"># loads the household_calculated.parquet file and retains 5 minute intervals and drops unnecessary columns.</span>
<span class="n">resample_hh_data</span><span class="p">(</span><span class="n">intervals</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;60min&quot;</span><span class="p">,</span> <span class="s2">&quot;15min&quot;</span><span class="p">])</span> <span class="c1"># loads the household_calculated.parquet file and resamples to 60min and 15min intervals in two separate datasets and drops unnecessary columns.</span>

</pre></div>
</div>
</section>
<section id="aggregation-of-household-data-to-project-level-data">
<h3>Aggregation of household data to project level data<a class="headerlink" href="#aggregation-of-household-data-to-project-level-data" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.aggregate</span><span class="w"> </span><span class="kn">import</span> <span class="n">read_hh_data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.calculated_columns</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_calculated_columns_to_hh_data</span>
<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="c1"># all files are saved to household_[interval].parquet in the aggregate folder, e.g. household_5min.parquet</span>
<span class="n">resample_hh_data</span><span class="p">(</span><span class="n">intervals</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;5min&quot;</span><span class="p">])</span> <span class="c1"># loads the household_calculated.parquet file and retains 5 minute intervals and drops unnecessary columns.</span>
<span class="n">resample_hh_data</span><span class="p">(</span><span class="n">intervals</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;60min&quot;</span><span class="p">,</span> <span class="s2">&quot;15min&quot;</span><span class="p">])</span> <span class="c1"># loads the household_calculated.parquet file and resamples to 60min and 15min intervals in two separate datasets and drops unnecessary columns.</span>

<span class="c1"># all files are saved to project_[interval].parquet in the aggregate folder, e.g. project_5min.parquet</span>
<span class="n">aggregate_project_data</span><span class="p">(</span><span class="n">intervals</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;5min&quot;</span><span class="p">])</span> <span class="c1"># aggregates all households and calculated project averages for all 5 minute intervals</span>
<span class="n">aggregate_project_data</span><span class="p">(</span><span class="n">intervals</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;60min&quot;</span><span class="p">,</span> <span class="s2">&quot;15min&quot;</span><span class="p">])</span> <span class="c1"># aggregates all households and calculated project averages for resampled 60min and 15min intervals</span>

</pre></div>
</div>
</section>
</section>
<section id="loading-complete-datasets-at-once">
<h2>Loading complete datasets at once<a class="headerlink" href="#loading-complete-datasets-at-once" title="Link to this heading"></a></h2>
<p>It is not recommended to load the complete datasets in one go. It will take a lot of time to load and require a significant amount of RAM to store all the data in memory at once. Rather use <code class="docutils literal notranslate"><span class="pre">get_hh_table()</span></code> as described above.`</p>
<p>Some of the older workflows still do this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">etdtransform.aggregate</span><span class="w"> </span><span class="kn">import</span> <span class="n">read_hh_data</span>

<span class="n">etdtransform</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">aggregate_folder</span> <span class="o">=</span> <span class="s1">&#39;aggregate_folder_path&#39;</span> <span class="c1"># path to folder where aggregated files are stored</span>

<span class="c1"># Load household data before any imputation has been done</span>
<span class="n">df_combined</span>  <span class="o">=</span> <span class="n">read_hh_data</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">)</span>

<span class="c1"># Load household data that has been imputed, including all `is_imputed` columns for indentifying values as imputed</span>
<span class="n">df_imputed</span> <span class="o">=</span> <span class="n">read_hh_data</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="s2">&quot;imputed&quot;</span><span class="p">)</span>

<span class="c1"># Load household data that has been imputed with additional calculated columns</span>
<span class="n">df_calculated</span> <span class="o">=</span> <span class="n">read_hh_data</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="s2">&quot;calculated&quot;</span><span class="p">)</span>

<span class="c1"># Load household data that has been</span>
<span class="n">df_5min</span> <span class="o">=</span> <span class="n">read_hh_data</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="s2">&quot;5min&quot;</span><span class="p">)</span>

</pre></div>
</div>
</section>
<section id="weather-data">
<h2>Weather data<a class="headerlink" href="#weather-data" title="Link to this heading"></a></h2>
<p>Weather data is downloaded from KNMI and combined with project metadata to identify weather data for the closest weather station for each project. Weather data is merged with household and project datasets based on the available 1 hour resolution data. This occurs during the loading step and can be skipped to speed up data processing during analysis should the weather data not be required.</p>
</section>
</section>
<section id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Link to this heading"></a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="source/modules.html" class="btn btn-neutral float-right" title="etdtransform" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Nicolas Dickinson, Marten Witkamp, Petra Izeboud.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>